{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Traffic Sign Recognition using CNN"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is my implementation of the Tutorial [Traffic Sign Recognision using CNN](https://data-flair.training/blogs/python-project-traffic-signs-recognition/). It is one of the projects in [DataFlairâ€™s series of machine learning projects](https://data-flair.training/blogs/python-machine-learning-project-detecting-parkinson-disease/).\n",
    "In this notebook, we will develop and train the ML model using PyTorch which we can later package into a standalone applications."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For training the model we will use the [Traffic Sign Dataset](http://benchmark.ini.rub.de/?section=gtsrb&subsection=dataset). It was made available in 2011 as part of a competition at the International Joint Conference on Neural Networks (IJCNN). The dataset contains  43 classes and over 50,000 images in total.  It is about 300 MB in size and the Training set can be downloaded from this [link](http://benchmark.ini.rub.de/Dataset/GTSRB_Final_Training_Images.zip) and the test set can be downloaded from this [link](http://benchmark.ini.rub.de/Dataset/GTSRB_Final_Test_Images.zip)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Once you download the dataset, it contains 3 folders: Train, Test and Meta.\n",
    "\n",
    "<img src=\"images/dataset folders.png\" width=\"200px\" />\n",
    "\n",
    "Inside the *Train* folder there are 43 folders labeled from 0 to 42 and each folder contains images for a specific class."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading the training data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import time\n",
    "from PIL import Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = [] #images stored as np array\n",
    "y = [] #class labels (0 to 42)\n",
    "\n",
    "classes = 43\n",
    "current_path = os.getcwd()\n",
    "\n",
    "for i in range(classes):\n",
    "    path = os.path.join(current_path, 'data', 'train', str(i))\n",
    "    images = os.listdir(path)\n",
    "    \n",
    "    for img_name in images:\n",
    "        image = Image.open(path + '\\\\' + img_name)\n",
    "        image = image.resize((30, 30))\n",
    "        image = np.array(image)\n",
    "        X.append(image)\n",
    "        y.append(i)\n",
    "        \n",
    "X = np.array(X)\n",
    "y = np.array(y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Each image is resized to be of size 30x30 because that is what out neural network is expecting the input to be. Because each image is colored it has three channels (R,G,B), we expected our traning data to have the shape (N, 30, 30, 3) where N = total number of training instance [=39,209]."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(39209, 30, 30, 3)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# shape of training data\n",
    "X.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train/Test Split"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "At this point, it is a good idea to split the data into training data and testing data where the former is used in training the model while the later is used to evaluate its performance on unseen data before deploying it into a production environment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_test_split(data, labels, test_size=0.2, random_state=0):\n",
    "    np.random.seed(random_state)\n",
    "    N = labels.shape[0]\n",
    "    idx = np.random.permutation(N)\n",
    "    train_size = int(np.ceil((1-test_size)*N))\n",
    "    X_train = data[idx[:train_size]]\n",
    "    y_train = labels[idx[:train_size]]\n",
    "    X_test = data[idx[train_size:]]\n",
    "    y_test = labels[idx[train_size:]]\n",
    "    return X_train, X_test, y_train, y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train shape: (31368, 30, 30, 3)\n",
      "X_test shape: (7841, 30, 30, 3)\n",
      "y_train shape: (31368,)\n",
      "y_test shape: (7841,)\n"
     ]
    }
   ],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=113)\n",
    "print(f\"X_train shape: {X_train.shape}\")\n",
    "print(f\"X_test shape: {X_test.shape}\")\n",
    "print(f\"y_train shape: {y_train.shape}\")\n",
    "print(f\"y_test shape: {y_test.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Building the Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "to classify the images we will build a CNN model that has the following architecture:\n",
    "\n",
    "`CONV2D -> CONV2D -> MAXPOOL -> DROPOUT -> CONV2D -> CONV2D -> MAXPOOL -> DROPOUT --> FLATTEN -> FULLYCONNECTED -> DROPOUT -> FULLYCONNECTED`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import TensorDataset\n",
    "from torch.utils.data import DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Net(nn.Module):\n",
    "    \n",
    "    def __init__(self):\n",
    "        super(Net, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(3, 32, 5) #output (26,26,32)\n",
    "        self.conv2 = nn.Conv2d(32, 32, 5) #output (22,22,32)\n",
    "        self.pool1 = nn.MaxPool2d(2,2) #output (11,11,32)\n",
    "        self.dropout1 = nn.Dropout(0.25) #output (11,11,32)\n",
    "        self.conv3 = nn.Conv2d(32, 64, 3) #output(9,9,64)\n",
    "        self.conv4 = nn.Conv2d(64, 64, 3) #output (7,7,64)\n",
    "        self.pool2 = nn.MaxPool2d(2,2)  #output (3,3,64)\n",
    "        self.dropout2 = nn.Dropout(0.25) #output (3,3,64)\n",
    "        self.fc1 = nn.Linear(3*3*64,256) #output (256, 1)\n",
    "        self.dropout3 = nn.Dropout(0.5) #output (256, 1)\n",
    "        self.fc2 = nn.Linear(256, 43) #output (43, 1)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = F.relu(self.conv1(x))\n",
    "        x = F.relu(self.conv2(x))\n",
    "        x = self.pool1(x)\n",
    "        x = self.dropout1(x)\n",
    "        x = F.relu(self.conv3(x))\n",
    "        x = F.relu(self.conv4(x))\n",
    "        x = self.pool2(x)\n",
    "        x = self.dropout2(x)\n",
    "        x = x.view(-1, 3*3*64)\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = self.dropout3(x)\n",
    "        x = self.fc2(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Net(\n",
       "  (conv1): Conv2d(3, 32, kernel_size=(5, 5), stride=(1, 1))\n",
       "  (conv2): Conv2d(32, 32, kernel_size=(5, 5), stride=(1, 1))\n",
       "  (pool1): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "  (dropout1): Dropout(p=0.25, inplace=False)\n",
       "  (conv3): Conv2d(32, 64, kernel_size=(3, 3), stride=(1, 1))\n",
       "  (conv4): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1))\n",
       "  (pool2): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "  (dropout2): Dropout(p=0.25, inplace=False)\n",
       "  (fc1): Linear(in_features=576, out_features=256, bias=True)\n",
       "  (dropout3): Dropout(p=0.5, inplace=False)\n",
       "  (fc2): Linear(in_features=256, out_features=43, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = Net()\n",
    "model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "we will use the cross entroy loss and the adam optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train the model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "we will train the model using batch size of 64 and for 15 epochs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data loaded as (batch, width, height, channels) \n",
    "# but pytorch expects (batch,channels, width, height) \n",
    "X_train_tensor = torch.from_numpy(np.transpose(X_train, (0, 3, 1, 2))).float()\n",
    "y_train_tensor = torch.from_numpy(y_train).long()\n",
    "X_val_tensor = torch.from_numpy(np.transpose(X_test, (0, 3, 1, 2))).float()\n",
    "y_val_tensor = torch.from_numpy(y_test).long()\n",
    "train_data = TensorDataset(X_train_tensor, y_train_tensor)\n",
    "val_data = TensorDataset(X_val_tensor, y_val_tensor)\n",
    "train_dataloader = DataLoader(dataset=train_data, batch_size=64)\n",
    "val_dataloader = DataLoader(dataset=val_data, batch_size=64)\n",
    "dataloaders = {'train': train_dataloader, 'val':val_dataloader}\n",
    "dataset_sizes = {'train': len(X_train), 'val': len(X_test)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(model, criterion, optimizer, dataset_sizes, num_epochs=15):\n",
    "    \n",
    "    since = time.time()\n",
    "    epoch_loss = []\n",
    "    epoch_acc = []\n",
    "    \n",
    "    for epoch in range(num_epochs):\n",
    "        print('Epoch {}/{}'.format(epoch, num_epochs - 1))\n",
    "        print('-' * 10)\n",
    "\n",
    "        # Each epoch has a training and validation phase\n",
    "        for phase in ['train', 'val']:\n",
    "            if phase == 'train':\n",
    "                model.train()  # Set model to training mode\n",
    "            else:\n",
    "                model.eval()   # Set model to evaluate mode\n",
    "\n",
    "            i = 0\n",
    "            running_loss = 0.0\n",
    "            running_corrects = 0\n",
    "            \n",
    "            if phase == 'train':\n",
    "                 print(f'\\rProgress:',end='')\n",
    "                       \n",
    "            # Iterate over data.\n",
    "            for inputs, labels in dataloaders[phase]:\n",
    "\n",
    "                # zero the parameter gradients\n",
    "                optimizer.zero_grad()\n",
    "\n",
    "                # forward\n",
    "                with torch.set_grad_enabled(phase == 'train'):\n",
    "                    outputs = model(inputs)\n",
    "                    _, preds = torch.max(outputs, 1)\n",
    "                    loss = criterion(outputs, labels)\n",
    "\n",
    "                    if phase == 'train':\n",
    "                        loss.backward()\n",
    "                        optimizer.step()\n",
    "\n",
    "                # statistics\n",
    "                running_loss += loss.item()\n",
    "                running_corrects += torch.sum(preds == labels.data)\n",
    "                if phase == 'train' and i % 50 == 49:\n",
    "                    print(f\"\\rProgress: [{'='*((i+1)//50)}] \",end='')\n",
    "                i += 1\n",
    "                                  \n",
    "            epoch_loss.append(running_loss / dataset_sizes[phase])\n",
    "            epoch_acc.append(running_corrects.numpy() / dataset_sizes[phase])\n",
    "\n",
    "            print('{} Loss: {:.4f} Acc: {:.4f}'.format(\n",
    "                phase, epoch_loss[-1], epoch_acc[-1]))\n",
    "\n",
    "        print()\n",
    "\n",
    "    time_elapsed = time.time() - since\n",
    "    print('Training complete in {:.0f}m {:.0f}s'.format(\n",
    "        time_elapsed // 60, time_elapsed % 60))\n",
    "\n",
    "    return epoch_loss, epoch_acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0/14\n",
      "----------\n",
      "Progress: [=========] train Loss: 0.0280 Acc: 0.4966\n",
      "val Loss: 0.0086 Acc: 0.8652\n",
      "\n",
      "Epoch 1/14\n",
      "----------\n",
      "Progress: [=========] train Loss: 0.0100 Acc: 0.8148\n",
      "val Loss: 0.0043 Acc: 0.9410\n",
      "\n",
      "Epoch 2/14\n",
      "----------\n",
      "Progress: [=========] train Loss: 0.0066 Acc: 0.8723\n",
      "val Loss: 0.0024 Acc: 0.9570\n",
      "\n",
      "Epoch 3/14\n",
      "----------\n",
      "Progress: [=========] train Loss: 0.0054 Acc: 0.8982\n",
      "val Loss: 0.0018 Acc: 0.9689\n",
      "\n",
      "Epoch 4/14\n",
      "----------\n",
      "Progress: [=========] train Loss: 0.0050 Acc: 0.9072\n",
      "val Loss: 0.0024 Acc: 0.9557\n",
      "\n",
      "Epoch 5/14\n",
      "----------\n",
      "Progress: [=========] train Loss: 0.0049 Acc: 0.9071\n",
      "val Loss: 0.0019 Acc: 0.9670\n",
      "\n",
      "Epoch 6/14\n",
      "----------\n",
      "Progress: [=========] train Loss: 0.0044 Acc: 0.9183\n",
      "val Loss: 0.0014 Acc: 0.9764\n",
      "\n",
      "Epoch 7/14\n",
      "----------\n",
      "Progress: [=========] train Loss: 0.0040 Acc: 0.9237\n",
      "val Loss: 0.0016 Acc: 0.9719\n",
      "\n",
      "Epoch 8/14\n",
      "----------\n",
      "Progress: [=========] train Loss: 0.0040 Acc: 0.9242\n",
      "val Loss: 0.0018 Acc: 0.9674\n",
      "\n",
      "Epoch 9/14\n",
      "----------\n",
      "Progress: [====] "
     ]
    }
   ],
   "source": [
    "epoch_loss, epoch_acc = train_model(model, criterion, optimizer, dataset_sizes, num_epochs=15)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "our model got x% accuracy on the training dataset. we can plot a graph of the loss. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot loss\n",
    "accuracy = epoch_acc[::2]\n",
    "val_accuracy = epoch_acc[1::2]\n",
    "loss = epoch_loss[::2]\n",
    "val_loss = epoch_loss[1::2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#plot accuracy\n",
    "plt.figure()\n",
    "plt.plot(accuracy, label = 'Training Accuracy')\n",
    "plt.plot(val_accuracy, label = 'Validation Accuracy')\n",
    "plt.title('Accuray')\n",
    "plt.xlabel('epochs')\n",
    "plt.ylabel('accuracy')\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#plot loss\n",
    "plt.figure()\n",
    "plt.plot(loss, label = 'Training Loss')\n",
    "plt.plot(val_loss, label = 'Validation Loss')\n",
    "plt.title('Loss')\n",
    "plt.xlabel('epochs')\n",
    "plt.ylabel('loss')\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Testing the model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The dataset contains a test folder and a `test.csv` that contains the correct labels. We will use these data to calculate the accuray of the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#load the csv file\n",
    "test_model_data = np.loadtxt(open(\"test.csv\", \"rb\"), delimiter=\",\", skiprows=1)\n",
    "\n",
    "y_test_labels = test_model_data[:,-2]\n",
    "img_paths = test_model_data[:-1]\n",
    "y_test_data = []\n",
    "\n",
    "#read images from disk\n",
    "for img in img_path:\n",
    "    image = Image.open(img)\n",
    "    image = image.resize((30,30))\n",
    "    y_test_data.append(np.array(image))\n",
    "    \n",
    "y_test_data = np.array(y_test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#predict the outputs\n",
    "y_test_outputs = model(y_test_data)\n",
    "_, y_test_preds = torch.max(y_test_outputs, 1)\n",
    "acc = torch.sum(y_test_preds == y_test_labels)/len(y_test_labels)\n",
    "print(f\"{acc:.2f%}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
